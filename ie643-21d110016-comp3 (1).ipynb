{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7112585,"sourceType":"datasetVersion","datasetId":4101357},{"sourceId":7112747,"sourceType":"datasetVersion","datasetId":4101474},{"sourceId":1418,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":1199}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-03T21:18:33.037586Z","iopub.execute_input":"2023-12-03T21:18:33.038531Z","iopub.status.idle":"2023-12-03T21:18:37.741407Z","shell.execute_reply.started":"2023-12-03T21:18:33.038497Z","shell.execute_reply":"2023-12-03T21:18:37.740485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install required packages\n!pip install -Uqq tf-nightly\n\n# Import necessary libraries\nimport tensorflow as tf\nfrom pathlib import Path\nimport pandas as pd\nfrom tqdm import tqdm\nfrom PIL import Image\n\n\n# Define the input dimensions for your YOLOv5 model\n# Assumptions \nmodel_input_width = 320  \nmodel_input_height = 320  \n\n\n# Load YOLOv5 model\nmodel_path = '/kaggle/input/yolo-v5/tflite/tflite-tflite-model/1/1.tflite'\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Load dataset\ndataset_path = '/kaggle/input/dataset'\ntrain_csv_path = Path(dataset_path) / 'train.csv'\ntest_csv_path = Path(dataset_path) / 'test.csv'\n\ntrain_df = pd.read_csv(train_csv_path)\ntest_df = pd.read_csv(test_csv_path)\n\n\n# Create a dictionary to map object labels to numerical identifiers\nlabel_mapping = {'pedestrian': 1, 'people': 2, 'bicycle': 3, 'car': 4, 'van': 5, 'truck': 6, 'tricycle': 7, 'awning-tricycle': 8, 'bus': 9, 'motor': 10, 'others': 11}\n\n\n# Preprocess the dataset\ndef preprocess_image(image_path,model_input_width, model_input_height):\n    # Implement preprocessing steps as needed\n    img = Image.open(image_path)\n    img = img.resize((model_input_width, model_input_height))  #resize\n    img_array = tf.keras.preprocessing.image.img_to_array(img)\n    img_array = tf.expand_dims(img_array, 0)\n    return img_array\n\ndef process_output(output_data):\n    # Implement processing of the YOLOv5 output data\n    # Extracting bounding box coordinates, confidence scores, and class predictions\n    bounding_boxes = output_data[:, :, :4]\n    confidence_scores = output_data[:, :, 4]\n    class_predictions = output_data[:, :, 5:]\n\n    return bounding_boxes, confidence_scores, class_predictions\n\n\n# collect result after Running inference on the dataset\nresults = []\n\nfor index, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"Running Inference\"):\n    image_path = Path(dataset_path) / 'images' / f\"{row['id']}.jpg\"  # Update the path to 'images'\n    \n    # Check if the image file exists\n    if not image_path.is_file():\n        print(f\"Image not found: {image_path}\")\n        continue\n    \n    image_data = preprocess_image(image_path, model_input_width, model_input_height)\n\n    # Initialize YOLO annotations list\n    annotations = row['annotations'].split('|')\n    \n    yolo_annotations = []\n\n    for annotation in annotations:\n        bbox_info = annotation.split(',')\n        print(\"bbox_info:\", bbox_info)\n    \n    # Make sure there are at least 5 elements in bbox_info\n        if len(bbox_info) >= 5:\n            bbox_left_str, bbox_top_str, bbox_width_str, bbox_height_str, object_label_str = bbox_info[:5]\n\n    # Convert string variables to integers\n            bbox_left, bbox_top, bbox_width, bbox_height = map(int, [bbox_left_str, bbox_top_str, bbox_width_str, bbox_height_str])\n    \n    # Map the object label string to a numerical identifier\n            object_label = label_mapping.get(object_label_str, -1)\n            \n            if object_label != -1:\n                center_x = (bbox_left + bbox_width / 2) / model_input_width\n                center_y = (bbox_top + bbox_height / 2) / model_input_height\n                normalized_width = bbox_width / model_input_width\n                normalized_height = bbox_height / model_input_height\n\n                yolo_annotations.append(f\"{object_label} {center_x} {center_y} {normalized_width} {normalized_height}\")\n            else:\n                print(f\"Invalid label: {object_label_str}\")\n            \n    # Combine YOLO annotations with line break\n    yolo_annotations_str = \"\\n\".join(yolo_annotations)\n    # Define the input and output tensor indices\n     # Define the input and output tensor indices\n    input_tensor_index = interpreter.get_input_details()[0]['index']\n    output_tensor_index = interpreter.get_output_details()[0]['index']\n\n    # Perform inference\n    interpreter.set_tensor(input_tensor_index, image_data)\n    interpreter.invoke()\n    output_data = interpreter.get_tensor(output_tensor_index)\n\n    # Process the output data as needed\n    # Save results for evaluation\n    results.append({\n        'image_filename': row['id'],\n        'predicted_boxes': process_output(output_data),\n        \n    })\n\n\n# Save the trained model\nmodel.save('/kaggle/working/yolov5_model')\n\n# Save the model weights\nmodel.save_weights('/kaggle/working/yolov5_model_weights.h5')","metadata":{"execution":{"iopub.status.busy":"2023-12-03T21:18:37.743515Z","iopub.execute_input":"2023-12-03T21:18:37.744133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load test dataset\ntest_df = pd.read_csv(test_csv_path)\n\n# Create an empty list to store the results for submission\nsubmission_results = []\n\n# Run inference on the test dataset\nfor index, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Running Inference on Test Set\"):\n    image_path = Path(dataset_path) / 'images' / f\"{row['id']}.jpg\"\n\n    # Check if the image file exists\n    if not image_path.is_file():\n        print(f\"Image not found: {image_path}\")\n        continue\n\n    # Preprocess the image\n    image_data = preprocess_image(image_path, model_input_width, model_input_height)\n\n    # Perform inference\n    interpreter.set_tensor(input_tensor_index, image_data)\n    interpreter.invoke()\n    output_data = interpreter.get_tensor(output_tensor_index)\n\n    # Process the output data\n    predicted_boxes, confidence_scores, class_predictions = process_output(output_data)\n\n    # Convert these predictions to the required annotation format\n    annotations = []\n\n    for i in range(len(predicted_boxes)):\n        bbox = predicted_boxes[i]\n        confidence = confidence_scores[i]\n        class_prediction = class_predictions[i]\n\n        # Convert bbox coordinates to integers\n        bbox = bbox.astype(int)\n\n        # Get the predicted object label (assuming class_predictions is a one-hot encoded vector)\n        object_label = np.argmax(class_prediction) + 1  # +1 because class indices start from 1 in your label_mapping\n\n        # Format the annotation string\n        annotation_str = f\"{bbox[0]},{bbox[1]},{bbox[2]},{bbox[3]},{confidence},{object_label}\"\n\n        annotations.append(annotation_str)\n\n    # Combine multiple object annotations with the pipe symbol\n    annotations_str = \"|\".join(annotations)\n\n    # Append results to the submission list\n    submission_results.append({'id': row['id'], 'annotations': f\"[{annotations_str}]|{object_label}\"})\n\n# Create a DataFrame for submission\nsubmission_df = pd.DataFrame(submission_results)\n\n# Save the submission file\nsubmission_df.to_csv('submission3.csv', index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}